
# Домашнее задание к занятию "13.Системы мониторинга"

## Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя 
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой 
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?

<details>  
<summary> Ответ на вопрос №1 </summary>  

Я бы выделил **три уровня метрик** и собрал бы следующий минимальный набор, ориентируясь на **Four Golden Signals** (Latency, Traffic, Errors, Saturation).

#### Уровень 1: Бизнес-логика (Самое важное для пользователя)

Эти метрики отвечают на вопрос "Работает ли сервис так, как нужно конечному пользователю?".

1.  **Скорость формирования отчетов (Latency):**
    *   **Что:** `http_request_duration_seconds` (гистограмма). Замеряем время от получения HTTP-запроса до момента отправки ответа клиенту.
    *   **Почему:** Пользователь напрямую ощущает эту задержку. Высокое время выполнения — главный признак проблем.
    *   **Детали:** Обязательно нужно измерять квантили (p50, p95, p99). p99 покажет наихудший опыт самых "невезучих" пользователей.

2.  **Количество запросов (Traffic):**
    *   **Что:** `http_requests_total` (счетчик). Общее количество входящих HTTP-запросов.
    *   **Почему:** Показывает нагрузку на сервис. Резкий рост или падение (до 0) — critical-алерт.

3.  **Количество успешных и неуспешных операций (Errors):**
    *   **Что:** `http_requests_total{status=~"5.."}` (счетчик) и `http_requests_total{status=~"2.."}`. Считаем ответы с кодами 5xx (ошибки сервера) и 2xx (успех).
    *   **Почему:** Прямой индикатор доступности сервиса. Рост 5xx- ошибок означает, что пользователи не могут получить свои отчеты.
    *   **Дополнительно:** Можно добавить счетчик 4xx-ошибок для отслеживания проблем с клиентскими запросами.

#### Уровень 2: Инфраструктура и ресурсы

Эти метрики отвечают на вопрос "Почему сервис работает медленно или с ошибками?".

1.  **Загрузка CPU (Saturation):**
    *   **Что:** `node_cpu_usage` или `process_cpu_seconds_total`. Загрузка процессора в процентах (на уровне всей виртуалки/контейнера) или конкретного процесса.
    *   **Почему:** Прямо указано, что вычисления нагружают ЦПУ. Это ключевой ресурс для вашего сервиса. Высокая загрузка (например, >80% продолжительное время) — признак необходимости масштабирования или оптимизации кода.

2.  **Дисковое I/O и свободное место (Saturation):**
    *   **Что:**
        *   `node_disk_io_time_seconds` (загрузка диска).
        *   `node_filesystem_avail_bytes` (свободное место на файловой системе).
    *   **Почему:** Отчеты сохраняются на диск. Если диск медленный или перегружен операциями записи, это будет напрямую влиять на общую latency. Заканчивающееся место — гарантированный даунтайм в будущем.

3.  **Потребление памяти (Saturation):**
    *   **Что:** `node_memory_MemAvailable_bytes` или `process_resident_memory_bytes`.
    *   **Почему:** Хоть основная нагрузка и на ЦПУ, вычисления часто используют оперативную память для хранения промежуточных данных. Нехватка памяти приведет к свопу (и жутким тормозам) или OOM-Kill процесса.

#### Уровень 3: Синтетические метрики (Опционально, но сильно повышает качество)

*   **Что:** Наличие простого скрипта (через Blackbox exporter или Synthetics), который периодически (например, раз в минуту) отправляет тестовый запрос на генерацию отчета и проверяет, что ответ приходит с кодом 200 и за приемлемое время.
*   **Почему:** Это самый надежный способ проверить доступность сервиса *с точки зрения пользователя*, а не просто факт работы процесса. Если процесс "висит", но не отвечает, метрики уровня 2 будут в норме, а этот тест упадет.

---

### Итоговый минимальный набор метрик для дашборды и алертинга:

| Метрика                              | Тип         | Зачем?                                                                |
| :----------------------------------- | :---------- | :-------------------------------------------------------------------- |
| **HTTP Request Duration (p95, p99)** | Гистограмма | **Основной индикатор производительности.**                            |
| **HTTP Request Rate**                | Счетчик     | **Понимание нагрузки.** Резкое падение = нет трафика или сервис умер. |
| **HTTP 5xx Error Rate**              | Счетчик     | **Аварийный алерт.** Пользователи не могут получить отчет.            |
| **CPU Utilization**                  | Gauge       | **Главный ресурсный ограничитель.** Рост ведет к росту latency.       |
| **Disk Space Available**             | Gauge       | **Аварийный алерт.** Закончится место — сервис упадет.                |
| **Disk I/O Utilization**             | Gauge       | **Вторичный фактор, влияющий на latency.**                            |
| **Memory Available**                 | Gauge       | **Ресурсное ограничение.**                                            |

**Почему такой набор минимальный и достаточный?**

Он покрывает все золотые сигналы и позволяет ответить на ключевые вопросы:
1.  **Доступен ли сервис для пользователя?** (Traffic, Errors)
2.  **Быстро ли он работает?** (Latency)
3.  **Есть ли риск сломаться из-за нехватки ресурсов?** (Saturation: CPU, Disk, Memory)
4.  **В чем наиболее вероятная причина проблемы?** (Совместный анализ: если latency растет вместе с CPU -> проблема в вычислениях; если latency растет, а CPU нет -> возможно, проблема с диском).

Это основа, от которой можно будет отталкиваться, добавляя более детальные метрики (например, потребление CPU конкретными endpoint'ами, количество сгенерированных отчетов и т.д.).
</details>  

#
2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, 
что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы 
можете ему предложить?  
<details>  
<summary> Ответ на вопрос №2 </summary>  
  
Я бы предложил перевести технические метрики на язык бизнеса, введя понятие **SLA (Service Level Agreement) / SLO (Service Level Objectives)**.

Вот что я предлагаю донести до менеджера и вывести на отдельный, понятный дашборд:

#### 1. Вместо "Непонятных RAM/CPU/Дисков" — Вводим Здоровье Системы (System Health Score)

Это высокоуровневый агрегированный показатель, который говорит "все хорошо" (зеленый) или "есть проблема" (желтый/красный). Его можно реализовать как статусную панель или "светофор".

**Пример:**
*   **ЗЕЛЕНЫЙ (Все отлично):** > 95% запросов обрабатываются успешно и быстрее 10 секунд.
*   **ЖЕЛТЫЙ (Деградация сервиса):** >5% запросов обрабатываются дольше 10 секунд или есть ошибки.
*   **КРАСНЫЙ (Сервис недоступен/критически медленный):** >10% ошибок или среднее время ответа > 30 секунд.

Цифры (10 сек, 5%) — это пример. Их нужно обсудить и зафиксировать как целевые показатели (SLO).

#### 2. Ключевые Бизнес-Метрики Качества Обслуживания (SLOs)

Вместо технических терминов, мы говорим на языке бизнеса. Вот что действительно важно для клиента:

| Что важно клиенту                    | Как это измерить (Метрика)                                                                                              | Как представить менеджеру                                                                                                          |
| :----------------------------------- | :---------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------- |
| **1. Сервис доступен и отвечает.**   | **Availability (Доступность)** <br> `(Всего запросов - Запросы с ошибкой 5xx) / Всего запросов * 100%`                  | **"Доступность сервиса: 99.95%"** <br> Цель: > 99.9% в месяц. Простой и понятный процент успешных запросов.                        |
| **2. Отчеты формируются БЫСТРО.**    | **Latency (Скорость ответа)** <br> Процент запросов, которые выполнились быстрее целевого времени (например, 5 секунд). | **"Скорость генерации отчетов: 98% отчетов создаются менее чем за 5 секунд"** <br> Это гораздо понятнее, чем "p95 latency = 4.3s". |
| **3. Отчеты формируются КОРРЕКТНО.** | **Error Rate (Частота ошибок)** <br> `(Количество запросов с ошибкой 5xx / Всего запросов) * 100%`                      | **"Частота ошибок: 0.1%"** <br> Показывает, как часто у клиентов что-то ломается.                                                  |
| **4. Сервис не перегружен.**         | **Throughput (Производительность)** <br> `Количество успешно сгенерированных отчетов в минуту/час`                      | **"Мы стабильно обрабатываем ~100 отчетов в час"** <br> Показывает мощность системы и помогает планировать нагрузку.               |

#### 3. Как это визуализировать: Дашборд для Менеджера Продукта

Нужен простой и наглядный дашборд, который можно понять за 5 секунд.

**Верхняя панель:**
*   **Большие цифры (KPI):**
    *   `Доступность за сегодня: 99.98%`
    *   `Среднее время ответа: 1.2 сек`
    *   `Отчетов создано сегодня: 12,458`
*   **Светофор/статус:** **ЗЕЛЕНЫЙ** (Система работает в рамках SLO)

**Графики ниже:**
1.  **График доступности за последнюю неделю.** (Линия, которая должна быть близка к 100%).
2.  **График скорости.** Две линии: "Среднее время ответа" и "Целевое время (SLO)", например, 5 сек. Наглядно видно, когда мы были хуже цели.
3.  **График количества ошибок в час.** Столбчатая диаграмма. Показывает, в какие часы были проблемы.
4.  **График нагрузки (количество успешных запросов в час).** Показывает пиковое время и общую загруженность.

---

#### Итог: Что предложить менеджеру

1.  **Перейти от технических метрик к бизнес-ориентированным SLO.**
2.  **Определить целевые цифры (SLO) вместе с ним:** "Какую скорость формирования отчета мы считаем приемлемой для клиента? 5 секунд? 10? Какой процент доступности мы гарантируем? 99.9%?"
3.  **Создать простой дашборд** с ключевыми показателями: **Доступность, Скорость, Качество (отсутствие ошибок), Нагрузка.**
4.  **Внедрить механизм оповещения** не о том, что "CPU загружен на 95%", а о том, что "Мы нарушили SLO по скорости ответа для 5% наших пользователей". Это *алерт, ориентированный на пользователя*.

Такой подход переводит диалог с технического "у нас все хорошо, потому что графики в норме" на деловой "мы выполняем свои обязательства перед клиентами на 99.9%, вот отчет".
</details>  

#
3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою 
очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, 
чтобы разработчики получали ошибки приложения?  
<details>  
<summary> Ответ на вопрос №3 </summary>  

#### Рекомендуемый план действий
Необходимо настроить сбор и анализ логов на open source решениях.
1.  **Быстрое решение на ближайшие пару недель:** Реализовать **bash-скрипт с webhook** для отправки ошибок в Slack/Telegram. Это даст разработчикам мгновенную обратную связь и займет минимум времени.
2.  **Среднесрочное и самое эффективное решение:** **Интегрировать Sentry** по бесплатному плану. Это даст разработчикам максимальное качество информации об ошибках с минимальными затратами на внедрение и поддержку.
3.  **Как только финансирование появится:** Перейти на платный план Sentry или развернуть собственный стек (Loki, Elasticsearch) для полного сбора всех логов, а не только ошибок.

**Главный посыл:** Нельзя собирать все логи -> фокусируемся только на самом важном — на **ошибках (ERROR/Exception)**. И доставляем их разработчикам максимально простым и дешевым способом.
</details>

#
4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. 
Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 
70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?
#
5. Опишите основные плюсы и минусы pull и push систем мониторинга.
#
6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

    - Prometheus 
    - TICK
    - Zabbix
    - VictoriaMetrics
    - Nagios
#
7. Склонируйте себе [репозиторий](https://github.com/influxdata/sandbox/tree/master) и запустите TICK-стэк, 
используя технологии docker и docker-compose.

В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (`http://localhost:8888`). 

P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим `Z`, например
`./data:/var/lib:Z`
#
8. Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.
        
    - Нажмите на кнопку Add a query
    - Изучите вывод интерфейса и выберите БД telegraf.autogen
    - В `measurments` выберите cpu->host->telegraf-getting-started, а в `fields` выберите usage_system. Внизу появится график утилизации cpu.
    - Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

Для выполнения задания приведите скриншот с отображением метрик утилизации cpu из веб-интерфейса.
#
9. Изучите список [telegraf inputs](https://github.com/influxdata/telegraf/tree/master/plugins/inputs). 
Добавьте в конфигурацию telegraf следующий плагин - [docker](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker):
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
```

Дополнительно вам может потребоваться донастройка контейнера telegraf в `docker-compose.yml` дополнительного volume и 
режима privileged:
```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список `measurments` в 
веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

